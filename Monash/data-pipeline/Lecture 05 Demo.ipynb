{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create entry points to spark\n",
    "from pyspark import SparkContext # Spark\n",
    "from pyspark.sql import SparkSession # Spark SQL\n",
    "\n",
    "# We add this line to avoid an error : \"Cannot run multiple SparkContexts at once\". \n",
    "# If there is an existing spark context, we will reuse it instead of creating a new context.\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# local[*]: run Spark locally with as many working processors as logical cores on your machine.\n",
    "# In the field of `master`, we use a local server with as many working processors (or threads) as possible (i.e. `local[*]`). \n",
    "# If we want Spark to run locally with 'k' worker threads, we can specify as `local[k]`.\n",
    "# The `appName` field is a name to be shown on the Sparking cluster UI. \n",
    "\n",
    "# If there is no existing spark context, we now create a new context\n",
    "if (sc is None):\n",
    "    sc = SparkContext(master=\"local[*]\", appName=\"Lecture Demo Week 05\")\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam classification example\n",
    "The data is from UCI Machine Learning Repository and can be downloaded from [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/).\n",
    "\n",
    "According to the data describing the data is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged according to being ham (legitimate) or spam. We will tokenize the messages and create TF-IDF and then we will build models using cross-validation and grid search and compare the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|_c0 |_c1                                                                                                                                                        |\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|ham |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|spam|Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "|ham |U dun say so early hor... U c already then say...                                                                                                          |\n",
      "|ham |Nah I don't think he goes to usf, he lives around here though                                                                                              |\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df = spark.read.csv(\"SMSSpamCollection\", sep = \"\\t\", inferSchema = True, header = False)\n",
    "df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|message                                                                                                                                                    |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|ham  |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|spam |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "|ham  |U dun say so early hor... U c already then say...                                                                                                          |\n",
      "|ham  |Nah I don't think he goes to usf, he lives around here though                                                                                              |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "df = df.withColumnRenamed('_c0', 'label').withColumnRenamed('_c1', 'message')\n",
    "df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|message                                                                                                                                                    |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1.0  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|1.0  |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|0.0  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "|1.0  |U dun say so early hor... U c already then say...                                                                                                          |\n",
      "|1.0  |Nah I don't think he goes to usf, he lives around here though                                                                                              |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change the status column to numeric: ham to 1.0 and spam to 0. \n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = df.withColumn('label', when(df['label'] == 'ham', 1.0).otherwise(0.0))\n",
    "df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|message                                                                                                                                                    |words                                                                                                                                                                                   |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1.0  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |[go, until, jurong, point,, crazy.., available, only, in, bugis, n, great, world, la, e, buffet..., cine, there, got, amore, wat...]                                                    |\n",
      "|1.0  |Ok lar... Joking wif u oni...                                                                                                                              |[ok, lar..., joking, wif, u, oni...]                                                                                                                                                    |\n",
      "|0.0  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005., text, fa, to, 87121, to, receive, entry, question(std, txt, rate)t&c's, apply, 08452810075over18's]|\n",
      "|1.0  |U dun say so early hor... U c already then say...                                                                                                          |[u, dun, say, so, early, hor..., u, c, already, then, say...]                                                                                                                           |\n",
      "|1.0  |Nah I don't think he goes to usf, he lives around here though                                                                                              |[nah, i, don't, think, he, goes, to, usf,, he, lives, around, here, though]                                                                                                             |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the messages\n",
    "from pyspark.ml.feature import  Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "wordsData.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: CountVectorizer\n",
    "CountVectorizer converts the list of tokens above to vectors of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|             message|               words|         rawFeatures|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|(13587,[8,42,52,6...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|(13587,[5,75,411,...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|(13587,[0,3,8,20,...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|(13587,[5,22,60,1...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don't, t...|(13587,[0,1,66,87...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "count = CountVectorizer (inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "model = count.fit(wordsData)\n",
    "featurizedData = model.transform(wordsData)\n",
    "featurizedData.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(13587,[8,42,52,6...|\n",
      "|  1.0|(13587,[5,75,411,...|\n",
      "|  0.0|(13587,[0,3,8,20,...|\n",
      "|  1.0|(13587,[5,22,60,1...|\n",
      "|  1.0|(13587,[0,1,66,87...|\n",
      "|  0.0|(13587,[0,2,6,10,...|\n",
      "|  1.0|(13587,[0,7,9,13,...|\n",
      "|  1.0|(13587,[0,10,11,4...|\n",
      "|  0.0|(13587,[0,2,3,14,...|\n",
      "|  0.0|(13587,[0,4,5,10,...|\n",
      "|  1.0|(13587,[0,1,6,32,...|\n",
      "|  0.0|(13587,[0,6,40,46...|\n",
      "|  0.0|(13587,[0,2,3,4,8...|\n",
      "|  1.0|(13587,[0,1,2,3,4...|\n",
      "|  1.0|(13587,[1,3,14,16...|\n",
      "|  0.0|(13587,[0,4,8,11,...|\n",
      "|  1.0|(13587,[158,314,3...|\n",
      "|  1.0|(13587,[1,5,20,47...|\n",
      "|  1.0|(13587,[4,5,29,59...|\n",
      "|  0.0|(13587,[0,4,28,82...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import  IDF\n",
    "# IDF down-weighs features which appear frequently in a corpus. \n",
    "# This generally improves performance when using text as features since most frequent, \n",
    "# and hence less important words, get down-weighed.\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.select(\"label\", \"features\").show()  \n",
    "# We want only the label and features columns for our machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline\n",
    "\n",
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (80%) and testing (20%)\n",
    "seed = 0  # set seed for reproducibility\n",
    "trainDF, testDF = rescaledData.randomSplit([0.8,0.2],seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data:  4424\n",
      "Number of test data:  1150\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training data: \", trainDF.count())\n",
    "print(\"Number of test data: \", testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(13587,[8,42,52,6...|\n",
      "|  1.0|(13587,[5,75,411,...|\n",
      "|  0.0|(13587,[0,3,8,20,...|\n",
      "|  1.0|(13587,[5,22,60,1...|\n",
      "|  1.0|(13587,[0,1,66,87...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"label\", \"features\").show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Logistic Regression Classifier\n",
    "Logistic regression is a popular method to predict a categorical response. It is a special case of Generalized Linear models that predicts the probability of the outcomes. In spark.ml logistic regression can be used to predict a binary outcome by using binomial logistic regression, or it can be used to predict a multiclass outcome by using multinomial logistic regression.\n",
    "\n",
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'message',\n",
       " 'words',\n",
       " 'rawFeatures',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "\n",
    "lr = LogisticRegression(maxIter = 10)\n",
    "\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, np.linspace(0.3, 0.01, 10)) \\\n",
    "    .addGrid(lr.elasticNetParam, np.linspace(0.3, 0.8, 6)) \\\n",
    "    .build()\n",
    "crossval_lr = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid_lr,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds= 5)  \n",
    "\n",
    "cvModel_lr = crossval_lr.fit(trainDF)\n",
    "best_model_lr = cvModel_lr.bestModel.summary\n",
    "best_model_lr.predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 3831|\n",
      "|  0.0|       0.0|  593|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_fit_lr = best_model_lr.predictions.select('label','prediction')\n",
    "train_fit_lr.groupBy('label','prediction').count().show()\n",
    "\n",
    "# 3848 ham and 602 spams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How accurate is the model? \n",
    "# we use MulticlassClassificationEvaluator for the accuracy of the model\n",
    "# We can get the f1 score, accuracy, precision.\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_lr = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_lr.evaluate(best_model_lr.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'message',\n",
       " 'words',\n",
       " 'rawFeatures',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lr = cvModel_lr.transform(testDF)\n",
    "# As you can see below, the predictions dataframe contains the original data and the predictions.\n",
    "predictions_lr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|             message|               words|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|2p per min to cal...|[2p, per, min, to...|(13587,[0,10,11,1...|(13587,[0,10,11,1...|[7.48979684801116...|[0.99944155557299...|       0.0|\n",
      "|  0.0|3 FREE TAROT TEXT...|[3, free, tarot, ...|(13587,[0,10,11,5...|(13587,[0,10,11,5...|[3.35819247882461...|[0.96637208705479...|       0.0|\n",
      "|  0.0|5 Free Top Polyph...|[5, free, top, po...|(13587,[0,3,15,34...|(13587,[0,3,15,34...|[4.52658264760498...|[0.98929818725677...|       0.0|\n",
      "|  0.0|500 New Mobiles f...|[500, new, mobile...|(13587,[0,40,64,8...|(13587,[0,40,64,8...|[3.54605267190848...|[0.97197008438366...|       0.0|\n",
      "|  0.0|500 New Mobiles f...|[500, new, mobile...|(13587,[0,40,64,8...|(13587,[0,40,64,8...|[3.54605267190848...|[0.97197008438366...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show sample predictions\n",
    "predictions_lr.select('label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  994|\n",
      "|  0.0|       1.0|   33|\n",
      "|  1.0|       0.0|    2|\n",
      "|  0.0|       0.0|  121|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr.groupBy('label','prediction').count().show()\n",
    "# It missed 21 spam messages but it got the ham ones correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9695652173913043"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How accurate is the model?\n",
    "# we use MulticlassClassificationEvaluator for the accuracy of the model\n",
    "my_mc_lr = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_lr.evaluate(predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
